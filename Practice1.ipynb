{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Practice1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8SRweZEd4UIj"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luzinsan/OPD_neuro/blob/main/Practice1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SRweZEd4UIj"
      },
      "source": [
        "# ***Подготовка входных данных***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzGhMysYMNCi",
        "outputId": "fa9559a4-c206-45cf-c927-706980be22b6"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ecoli  ecoli.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B1iSeloMa8R",
        "outputId": "00556328-738d-4e15-9327-c1b1509d07b1"
      },
      "source": [
        "!unzip \"ecoli.zip\" -d \"ecoli\""
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ecoli.zip\n",
            "replace ecoli/ecoli.dat? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmT3BOuw3PWy"
      },
      "source": [
        "def load_keel(file_path):\n",
        "    file_path = Path(file_path)\n",
        "    return KeelParser()(file_path.read_text())"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Z07uQe3uYz"
      },
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "from pandas import DataFrame, Categorical, to_numeric\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "class DataScheme:\n",
        "    def __init__(self, data_name, attributes, inputs, outputs, X, y):\n",
        "        self.data_name = data_name\n",
        "        self.inputs = inputs\n",
        "        self.outputs = outputs\n",
        "        self.attributes = attributes\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "\n",
        "\n",
        "class KeelParser:\n",
        "    def __call__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "        data_name = self.get_data_name()\n",
        "        attributes = self.get_attributes()\n",
        "        inputs = self.get_inputs()\n",
        "        outputs = self.get_outputs()\n",
        "        data_frame = self.get_data()\n",
        "        data_frame.columns = [*inputs, *outputs]\n",
        "        X = np.array(data_frame[inputs])\n",
        "        y = np.array(data_frame[outputs]).ravel()\n",
        "\n",
        "        if len(outputs) > 1:\n",
        "            raise Exception('Multiple outputs in dataset not yet supported')\n",
        "        if attributes[outputs[0]][0] == 'nominal':\n",
        "            y = Categorical(\n",
        "                y,\n",
        "                ordered=False,\n",
        "                categories=attributes[outputs[0]][1]\n",
        "            ).codes\n",
        "        elif attributes[outputs[0]][0] == 'real':\n",
        "            y = np.array(y, dtype=float)\n",
        "        return DataScheme(data_name, attributes, inputs, outputs, X, y)\n",
        "\n",
        "    def get_data_name(self):\n",
        "        \"\"\"\n",
        "        Функция для получения названия набора данных\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        parsed = re.search(r'^@relation\\s+(\\S+)$', self.data, re.MULTILINE)\n",
        "        return parsed.group(1)\n",
        "\n",
        "    def get_attributes(self):\n",
        "        \"\"\"\n",
        "        Функция для получения описаний входных и выходных параметров\n",
        "        набора данных\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        attributes = dict()\n",
        "        if \"Attribute\" in self.data:\n",
        "            parsed = re.findall(r'^@Attribute\\s+(.+)$', self.data,\n",
        "                                re.MULTILINE)\n",
        "        else:\n",
        "            parsed = re.findall(r'^@attribute\\s+(.+)$', self.data,\n",
        "                                re.MULTILINE)\n",
        "\n",
        "        for att in parsed:\n",
        "            if '{' in att:\n",
        "                name = att[:att.index('{')].strip()\n",
        "                att = att[att.index('{'):]\n",
        "                for char in '{}':\n",
        "                    att = att.replace(char, '')\n",
        "                att = att.replace(\" \", \"\")\n",
        "                att = att.split(',')\n",
        "                attributes[name] = ['nominal', att]\n",
        "            else:\n",
        "                if 'real' in att or 'integer' in att:\n",
        "                    name = att[:att.index(' ')]\n",
        "                    att = att[att.index(' ') + 1:]\n",
        "                    att_type = att[:att.index('[')].strip()\n",
        "                    att = att[att.index('['):]\n",
        "                    for char in '[]':\n",
        "                        att = att.replace(char, '')\n",
        "                    attributes[name] = [\n",
        "                        att_type, att.replace(' ', '').split(',')]\n",
        "                else:\n",
        "                    if 'numeric' in att:\n",
        "                        att = att.split(' ')\n",
        "                        attributes[att[0].strip()] = ['numeric']\n",
        "                    else:\n",
        "                        raise Exception(\n",
        "                            f'Error during @attribute line parse: {att}')\n",
        "\n",
        "        return attributes\n",
        "\n",
        "    def get_inputs(self):\n",
        "        \"\"\"\n",
        "        Функция для получения списка входных параметров набора данных\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        parsed = re.search(r'^@inputs\\s+(.+)$', self.data, re.MULTILINE)\n",
        "        return [j.strip() for j in parsed.group(1).split(',')]\n",
        "\n",
        "    def get_outputs(self):\n",
        "        \"\"\"\n",
        "        Функция для получения списка выходных меток набора данных\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if \"outputs\" in self.data:\n",
        "            parsed = re.search(r'^@outputs\\s+(.+)$', self.data, re.MULTILINE)\n",
        "        else:\n",
        "            parsed = re.search(r'^@output\\s+(.+)$', self.data, re.MULTILINE)\n",
        "\n",
        "        return [x.strip() for x in parsed.group(1).split(',')]\n",
        "\n",
        "    def get_data(self):\n",
        "        \"\"\"\n",
        "        Функция для получения данных из выбранного набора\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        parsed = re.search(\n",
        "            r'^@data\\n(.+)', self.data, flags=re.MULTILINE | re.DOTALL)\n",
        "        data = np.array([\n",
        "            re.split(r', ?', item) for item in parsed.group(1).splitlines()])\n",
        "        dim = len(data[0])\n",
        "        ys = np.copy(data[:, dim - 1])\n",
        "        data[:, dim - 1] = 0\n",
        "        df = DataFrame(data=data)\n",
        "        df = df.apply(partial(to_numeric, errors='ignore'))\n",
        "        if not (df.select_dtypes(['object']).empty):\n",
        "            df.loc[:, df.dtypes == 'object'] = df.select_dtypes([\n",
        "                'object'\n",
        "            ]).apply(lambda x:\n",
        "                     (LabelEncoder().fit_transform(x)).astype('float'))\n",
        "        df[dim - 1] = df[dim - 1].astype(str)\n",
        "        df[dim - 1] = ys\n",
        "\n",
        "        return df"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlsPg89WMnIx"
      },
      "source": [
        "import os\n",
        "\n",
        "FILE_PATH = '/content/ecoli'\n",
        "MAIN_FILE_NAME = 'ecoli.dat'\n",
        "\n",
        "data = load_keel('/content/ecoli/ecoli.dat')\n",
        "\n",
        "ecoli = data"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSiDz5fOplbm"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI0vLMf89k8b"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp3iHLMD9dub"
      },
      "source": [
        "# ***Решение задачи регрессии***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpWTkopXwy7m",
        "outputId": "1ff26144-9bba-4d32-d029-ba1b1609128f"
      },
      "source": [
        "#Определение функции, создающей модель-регрессор\n",
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Большинство tf.keras моделей представляют собой простую последовательность слоев -\n",
        "  # sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Описание архитектуры модели\n",
        "  model.add(tf.keras.layers.Dense(units=1, \n",
        "                                  input_shape=(1,)))\n",
        "\n",
        "  # Компиляция модели\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model           \n",
        "\n",
        "print(\"Defined create_model\")\n"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined create_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChIm2Jta93Aw",
        "outputId": "910a2ccd-115b-4d80-a44a-7078e3722e87"
      },
      "source": [
        "def train_model(model, feature, label, epochs, batch_size):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Задание параметров обучения и запуск обучения\n",
        "  history = model.fit(x=feature,\n",
        "                      y=label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  # Получения параметров модели - линейного слоя\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  epochs = history.epoch\n",
        "  \n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, rmse\n",
        "\n",
        "print(\"Defined ctrain_model\")"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined ctrain_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftTjMlGex_VT",
        "outputId": "bc7070b4-9b47-4d8e-d78a-c14824f3659c"
      },
      "source": [
        "def plot_the_loss_curve(epochs, rmse):\n",
        "  \"\"\"График лосс-значений/эпохи\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, rmse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([rmse.min()*0.97, rmse.max()])\n",
        "  plt.show()\n",
        "\n",
        "print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the plot_the_model and plot_the_loss_curve functions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_azve9f8P1s"
      },
      "source": [
        "Определяем X, y (my_feature, label)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrySNbZiyBiH"
      },
      "source": [
        "my_feature = ([1.0, 2.0,  3.0,  4.0,  5.0,  6.0,  7.0,  8.0,  9.0, 10.0, 11.0, 12.0])\n",
        "my_label   = ([5.0, 8.8,  9.6, 14.2, 18.8, 19.5, 21.4, 26.8, 28.9, 32.0, 33.8, 38.2])"
      ],
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbQKisq5ygBd",
        "outputId": "748bab57-94ce-417e-c554-a724beecafd2"
      },
      "source": [
        "learning_rate=0.15\n",
        "epochs=40\n",
        "my_batch_size=12\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature, \n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 295ms/step - loss: 503.4810 - root_mean_squared_error: 22.4384\n",
            "Epoch 2/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 343.2309 - root_mean_squared_error: 18.5265\n",
            "Epoch 3/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 254.7260 - root_mean_squared_error: 15.9601\n",
            "Epoch 4/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 194.8823 - root_mean_squared_error: 13.9600\n",
            "Epoch 5/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 151.1450 - root_mean_squared_error: 12.2941\n",
            "Epoch 6/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 117.9013 - root_mean_squared_error: 10.8582\n",
            "Epoch 7/40\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 92.0806 - root_mean_squared_error: 9.5959\n",
            "Epoch 8/40\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 71.7850 - root_mean_squared_error: 8.4726\n",
            "Epoch 9/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.7409 - root_mean_squared_error: 7.4660\n",
            "Epoch 10/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 43.0406 - root_mean_squared_error: 6.5605\n",
            "Epoch 11/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 33.0070 - root_mean_squared_error: 5.7452\n",
            "Epoch 12/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 25.1170 - root_mean_squared_error: 5.0117\n",
            "Epoch 13/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.9562 - root_mean_squared_error: 4.3539\n",
            "Epoch 14/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.1891 - root_mean_squared_error: 3.7668\n",
            "Epoch 15/40\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.5411 - root_mean_squared_error: 3.2467\n",
            "Epoch 16/40\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.7855 - root_mean_squared_error: 2.7903\n",
            "Epoch 17/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7346 - root_mean_squared_error: 2.3947\n",
            "Epoch 18/40\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2333 - root_mean_squared_error: 2.0575\n",
            "Epoch 19/40\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1545 - root_mean_squared_error: 1.7761\n",
            "Epoch 20/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3948 - root_mean_squared_error: 1.5475\n",
            "Epoch 21/40\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8715 - root_mean_squared_error: 1.3680\n",
            "Epoch 22/40\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5196 - root_mean_squared_error: 1.2327\n",
            "Epoch 23/40\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2890 - root_mean_squared_error: 1.1353\n",
            "Epoch 24/40\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1420 - root_mean_squared_error: 1.0687\n",
            "Epoch 25/40\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0510 - root_mean_squared_error: 1.0252\n",
            "Epoch 26/40\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9964 - root_mean_squared_error: 0.9982\n",
            "Epoch 27/40\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9646 - root_mean_squared_error: 0.9821\n",
            "Epoch 28/40\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9465 - root_mean_squared_error: 0.9729\n",
            "Epoch 29/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9365 - root_mean_squared_error: 0.9677\n",
            "Epoch 30/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9310 - root_mean_squared_error: 0.9649\n",
            "Epoch 31/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9278 - root_mean_squared_error: 0.9632\n",
            "Epoch 32/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9258 - root_mean_squared_error: 0.9622\n",
            "Epoch 33/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9243 - root_mean_squared_error: 0.9614\n",
            "Epoch 34/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9231 - root_mean_squared_error: 0.9608\n",
            "Epoch 35/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9220 - root_mean_squared_error: 0.9602\n",
            "Epoch 36/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9209 - root_mean_squared_error: 0.9596\n",
            "Epoch 37/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9198 - root_mean_squared_error: 0.9591\n",
            "Epoch 38/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9187 - root_mean_squared_error: 0.9585\n",
            "Epoch 39/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9175 - root_mean_squared_error: 0.9579\n",
            "Epoch 40/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9163 - root_mean_squared_error: 0.9572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "x8bo1OrR6Kux",
        "outputId": "61c7aeee-fd7e-49dc-e474-b7fcc125c2da"
      },
      "source": [
        "plot_the_loss_curve(epochs, rmse)"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f3H8dcnG0gIK8ywh2wQ4wRFwb21rXv+bN3VlvZXbX9Wq62/WqvWaq2ravnZaqt1FKt1gYLWRUCmIBsJK2GFDRmf3x/3RK8x4xJyc26S9/PxOI97zvee8eFo8sk532XujoiISGVJYQcgIiKJSQlCRESqpAQhIiJVUoIQEZEqKUGIiEiVUsIOoD516NDBe/Xqtc/HzV+zlTYtU+nWpkX9ByUiksBmzJixwd1zqvquSSWIXr16kZ+fv8/Hnfvoh+wuLeef142OQ1QiIonLzFZW951eMQHDumWzYO1WSsrKww5FRCRhKEEAQ7tls7e0nCWF28MORUQkYShBEEkQAPNWF4cciYhI4mhSdRB11btDK1qmJTNvdTHfyesedjgiEoKSkhIKCgrYvXt32KHERUZGBrm5uaSmpsZ8jBIEkJxkDOnamnlrtoYdioiEpKCggKysLHr16oWZhR1OvXJ3Nm7cSEFBAb179475OL1iCgzpms1na7ZSVq7BC0Wao927d9O+ffsmlxwAzIz27dvv89OREkRgWLdsdpWUsaxIFdUizVVTTA4V6vJvU4IIVFRUz1VFtYgIoATxpb45rchITWLeatVDiEg4MjMzww7ha5QgAinJSQzq0lpNXUVEAkoQUYZ1y2b+mmLKVVEtIgli1qxZHHbYYQwfPpyzzjqLzZs3A/DAAw8wePBghg8fznnnnQfA1KlTGTlyJCNHjuTAAw9k27Zt+3VtNXONMrRrNv/34UqWb9xB35zEetQTkYZz+yvz+ayem70P7tqa204bss/HXXLJJTz44IOMHTuWW2+9ldtvv53777+fu+66i+XLl5Oens6WLVsAuOeee3jooYcYPXo027dvJyMjY79i1hNEFPWoFpFEUlxczJYtWxg7diwAl156KdOmTQNg+PDhXHjhhfzlL38hJSXyt/7o0aOZMGECDzzwAFu2bPmyvK70BBGlf6dM0lKSmLe6mDNGdgs7HBEJSV3+0m9or776KtOmTeOVV17hzjvvZO7cudx8882ccsopvPbaa4wePZo33niDgQMH1vkaeoKIkpqcxKDOWWrJJCIJITs7m7Zt2/Lee+8B8PTTTzN27FjKy8tZtWoVxxxzDL/5zW8oLi5m+/btLF26lGHDhnHTTTdx8MEHs3Dhwv26vp4gKhnaLZtJs9fg7k2604yIJJ6dO3eSm5v75faECROYOHEiV199NTt37qRPnz489dRTlJWVcdFFF1FcXIy7c8MNN9CmTRt+/vOf884775CUlMSQIUM46aST9iseJYhKhnbL5q8ff8EXm3bSs32rsMMRkWakvLzqOWk++uijb5S9//773yh78MEH6zUevWKqZJh6VIuIAEoQ39C/UyapyaZ6CBFp9pQgKklPSeaAzllq6irSDLk33U6ydfm3xS1BmFl3M3vHzD4zs/lmdmNQ3s7M3jKzxcFn22qOvzTYZ7GZXRqvOKsytGs289YUN+n/WUTk6zIyMti4cWOT/LmvmA9iXzvOxbOSuhT4kbvPNLMsYIaZvQVcBkx297vM7GbgZuCm6APNrB1wG5AHeHDsJHffHMd4vzS0WzZ/m76Kgs276N6uZUNcUkRClpubS0FBAUVFRWGHEhcVM8rti7glCHdfC6wN1reZ2QKgG3AGcHSw20TgXSolCOAE4C133wQQJJYTgWfjFW+0ih7V89cUK0GINBOpqan7NNtac9AgdRBm1gs4EPgY6BQkD4B1QKcqDukGrIraLgjKqjr3lWaWb2b59ZX5B3bOIjnJ1JJJRJq1uCcIM8sEXgB+4O5faxrkkZd9+/XCz90fc/c8d8/LycnZn1N9KSM1mf4dM9WSSUSatbgmCDNLJZIc/uruLwbF682sS/B9F6CwikNXA92jtnODsgYzrFs281arolpEmq94tmIy4AlggbvfF/XVJKCiVdKlwD+rOPwN4Hgzaxu0cjo+KGsww3Kz2bhjL+u27tsk3yIiTUU8nyBGAxcD48xsVrCcDNwFHGdmi4Fjg23MLM/M/gQQVE7/EpgeLHdUVFg3lCFdgx7VBaqHEJHmKZ6tmN4HqhvtbnwV++cD343afhJ4Mj7R1W5wl9YkGcxbs5Xjh3QOKwwRkdCoJ3U1WqQl069jpnpUi0izpQRRg6FBRbWISHOkBFGDoV2zKdy2h0JVVItIM6QEUYNhucEc1Wv0FCEizY8SRA0Gd2mNGcwtUIc5EWl+lCBq0Co9hT4dWukJQkSaJSWIWqiiWkSaKyWIWgzrls3a4t1s2L4n7FBERBqUEkQtvuxRracIEWlmlCBqMaJ7NmkpSby3aEPYoYiINCgliFq0TEvhiL7tmbxwvUZ2FZFmRQkiBuMHdWLlxp0sLdoedigiIg1GCSIG4wd2BODtBVVNXSEi0jQpQcSga5sWDO7SmskL1ocdiohIg1GCiNGxgzoyY+VmNu/YG3YoIiINQgkiRuMHdaLc4Z3P9ZpJRJqHeE45+qSZFZrZvKiyv0fNLrfCzGZVc+wKM5sb7Jcfrxj3xbBu2eRkpTNZ9RAi0kzUmCDMLNnM7qnjuf8MnBhd4O7nuvtIdx8JvAC8WMPxxwT75tXx+vUqKckYP7AjUxcVsbe0POxwRETirsYE4e5lwJi6nNjdpwFVziNtZgacAzxbl3OHZfygTmzfU8onyxt0emwRkVDE8orpUzObZGYXm9nZFct+XvdIYL27L67mewfeNLMZZnZlTScysyvNLN/M8ouKivYzrJqN6deB9JQk3lZrJhFpBmJJEBnARmAccFqwnLqf1z2fmp8exrj7KOAk4DozO6q6Hd39MXfPc/e8nJyc/QyrZi3Skhndr4N6VYtIs5BS2w7ufnl9XtDMUoCzgYNquObq4LPQzF4CDgGm1WccdTV+UEemLCxkceF2BnTKCjscEZG4qfUJwsxyzeyloEVSoZm9YGa5+3HNY4GF7l5QzfVamVlWxTpwPDCvqn3DMH5gJwC9ZhKRJi+WV0xPAZOArsHySlBWIzN7FvgQOMDMCszsiuCr86j0esnMuprZa8FmJ+B9M5sNfAK86u6vx/KPaQidszMY2q21mruKSJNX6ysmIMfdoxPCn83sB7Ud5O7nV1N+WRVla4CTg/VlwIgY4grN+IGdeGDKYjZu30P7zPSwwxERiYtYniA2mtlFQZ+IZDO7iEildbN17KBOuMM7n8e31ZSISJhiSRD/RaTPwjpgLfBtoF4rrhubod1a06l1Om9/pnoIEWm6anzFZGbJwP+6++kNFE+jYGaMG9iJSbNWs6e0jPSU5LBDEhGpd7H0pO5pZmkNFE+jceygjuzYW8ZHy9SrWkSaplgqqZcB/zGzScCOikJ3vy9uUTUCo/t1ICM1ickL1jN2QHw76ImIhCGWOoilwL+CfbOilmYtIzWZMf1ymLygUL2qRaRJiqUOYoC7X9hA8TQqxw7qyNsL1rNw3TYGdWkddjgiIvVKdRD7YVwwV7WmIhWRpkh1EPuhY+sMRuRm8/aCQq4f1z/scERE6pXqIPbT+EGdmF2whcKtu8MORUSkXsUymuvtlcuCEVkFOHlYF+57axEvfbqaq8b2DTscEZF6U+0ThJm9H7X+dKWvP4lbRI1Mv46ZHNSzLX/PX6XWTCLSpNT0iqlV1PrQSt9ZHGJptM7N686yoh3MWLk57FBEROpNTQnCq1mvartZO2V4F1qlJfP36avCDkVEpN7UVJfQxszOIpJE2kTNQ21Adtwja0Rapadw6vCuvDJnDbedPoTMdFXRiEjjV9MTxFTgdCLzT0/l6/NRJ8T0n4nknIO7s3NvGa/OWRN2KCIi9aLaP3X3dy5qM3uSSDIpdPehQdkvgO8BFRMp/MzdX6vi2BOB3wPJwJ/c/a79iaUhjOrRhn4dM/n79FWce3CPsMMREdlvsfSDqKs/AydWUf47dx8ZLFUlh2TgIeAkYDBwvpkNjmOc9cLMOCcvl5lfbGFJ4bawwxER2W9xSxDuPg2oy1jYhwBL3H2Zu+8F/gacUa/BxcnZo3JJSTJVVotIkxDPJ4jqXG9mc8zsSTNrW8X33YDo37AFQVnC65CZzvhBHXlx5mr2lpaHHY6IyH6ptg4iqtVSldz9xTpc72Hgl0Sayf4SuJfIlKZ1ZmZXAlcC9OgR/rv/cw/uzhvz1zNl4XpOHNol7HBEROqspvaYpwWfHYEjgCnB9jHAB8A+Jwh3/3LYUzN7nMgYT5WtBrpHbecGZdWd8zHgMYC8vLzQ+2cc1T+HTq3TeS6/QAlCRBq1al8xufvlQUumVGCwu3/L3b8FDAnK9pmZRf/GPAuYV8Vu04H+ZtY7GGb8PGBSXa4XhpTkJL41Kpd3Py9kXbEG8BORxiuWOoju7r42ans9UOu7HDN7FvgQOMDMCszsCuBuM5trZnOIPIn8MNi3q5m9BuDupcD1wBvAAuA5d5+/L/+osJ2T151yhxdmFoQdiohIncXS5Xeymb0BPBtsnwu8XdtB7n5+FcVPVLPvGuDkqO3XgG80gW0senVoxaG92/Fc/iquGduXpCQNXSUijU+tTxDufj3wCDAiWB5z9+/HO7DG7tyDu7Ny404+Xl6Xlr4iIuGLtZnrTOBVd/8h8IaZacKgWpw0tAtZ6Sk8n68+ESLSONWaIMzse8A/gEeDom7Ay/EMqilokZbM6SO78tq8tWzdXRJ2OCIi+yyWJ4jrgNHAVgB3X0yk6avU4py87uwuKWfSLA3gJyKNTywJYk8w5AXw5XSjofc3aAyG52YzsHOWht4QkUYplgQx1cx+BrQws+OA54FX4htW02BmXHBoD+auLmb6ClVWi0jjEkuCuInI8NxzgauIND+9JZ5BNSXfOag7bVum8si7S8MORURkn9TYDyIYenu+uw8EHm+YkJqWFmnJXHpEL+5/ezGL1m9jQCc1ABORxqHGJwh3LwM+N7PwR8FrxC49vBctUpN5dOqysEMREYlZLK+Y2gLzzWyymU2qWOIdWFPStlUa5x7cnX/OWs3a4l1hhyMiEpNYhtr4edyjaAauGNObpz9ayRPvLeeWUxN+gjwRkdoThLtPbYhAmrru7Vpy2vAuPPvJF3x/XH+yW9ZpQFwRkQYTS0/qw8xsupltN7O9ZlZmZlsbIrim5sqj+rJjbxl/+Xhl2KGIiNQqljqIPwDnA4uBFsB3gYfiGVRTNbhra8YOyOGp/yxnd0lZ2OGIiNQopsH63H0JkOzuZe7+FHBifMNquq4e25cN2/dqrggRSXixJIidwcxus8zsbjP7YYzHSRUO69OOEbnZPD5tGWXlGrFERBJXLL/oLwaSiczytoPIfNHfimdQTZmZcfXYvqzYuJM35q8LOxwRkWrF0oqpokZ1F3B7rCc2syeBU4FCdx8alP0WOA3YCywFLnf3LVUcuwLYBpQBpe6eF+t1G4Pjh3Smd4dWPDJ1KScN7YyZZpwTkcQTSyum5Wa2rPISw7n/zDfrKt4Chrr7cGAR8NMajj/G3Uc2teQAkJxkfO/IPswpKObDpRvDDkdEpEqxvGLKAw4OliOBB4C/1HaQu08DNlUqe9PdS4PNj4DcfYq2CTl7VDc6ZKbzyDQNvyEiiSmWOak3Ri2r3f1+4JR6uPZ/Af+u7rLAm2Y2w8yurOkkZnalmeWbWX5RUVE9hNUwMlKTuXx0L6YtKmL+muKwwxER+YZYXjGNilryzOxqYhuio6Zz/g9QCvy1ml3GuPso4CTgOjM7qrpzuftj7p7n7nk5OTn7E1aDu+iwnmSmp/CwhgIXkQQUyy/6e6PWS4EVwDl1vaCZXUak8nq8u1fZztPdVwefhWb2EnAIMK2u10xU2S1SueTwnvzx3aVcc3QxQ7pmhx2SiMiXYnnFdEzUcpy7f8/dP6/LxczsROAnwOnuvrOafVqZWVbFOnA8MK8u12sMrhrbl+wWqdz9ep1uqYhI3NT6BGFmE2r63t3vq+a4Z4GjgQ5mVgDcRqTVUjrwVtC08yN3v9rMugJ/cveTgU7AS8H3KcAz7v56zP+iRia7RSrXH9OPO19bwAdLNnBEvw5hhyQiAoBV85bnqx3MniHSgqliDojTgE+IjM2Eu8fcNyLe8vLyPD8/P+ww9tnukjLG3fMuOVnpvHzdaPWLEJEGY2YzqutOEEsz11xglLv/yN1/BBwE9HD32xMpOTRmGanJ/PC4AcwuKObf89S7WkQSQywJohORns8V9gZlUo/OHpXLgE6Z/PaNzykpKw87HBGRmBLE/wGfmNkvzOx24GMivaSlHiUnGTedOJDlG3bw9+mrwg5HRCSmVkx3ApcDm4GNRMZP+nW8A2uOxg3syMG92vL7yYvZube09gNEROKo2gRhZi3NLBXA3WcCrxMZ1bV3A8XW7JgZN580kKJte3jy/eVhhyMizVxNTxCvA70AzKwf8CHQh0jP5rviH1rzdFDPdhw3uBOPTF3Gph17az9ARCROakoQbd19cbB+KfCsu3+fyPAX9TEWk1TjJyccwM69pTz0zpKwQxGRZqymBBHdQWIckaG6cfe9gJrZxFH/Tll856DuPP3hSlZtqrLDuYhI3NWUIOaY2T3BFKP9gDcBzKxNg0TWzP3guP6Ywe/eWhR2KCLSTNWUIL4HbCBSD3F81NhJg4F74hxXs9cluwWXje7FS7NWs2Dt1rDDEZFmqNoE4e673P0ud7/R3WdHlX/g7k83THjN27Vj+9E6I5U7XvmM2oZEERGpb7F0lJOQZLdM5ccnHMCHyzYyafaasMMRkWZGCSLBXXBID0bkZvPLfy2geFdJ2OGISDOiBJHgkpOMX505jE079nDfm5ozQkQaTixTjg4ws8fN7E0zm1KxNERwEjEsN5uLD+vJ0x+tZG6B5q8WkYYRyxPE88BM4Bbgv6MWaUA/OuEA2rVK55aX51JWrgprEYm/WBJEqbs/7O6fuPuMiiWWk5vZk2ZWaGbzosramdlbZrY4+GxbzbGXBvssNrNLY/z3NFmtM1L5+amDmF1QzDOffBF2OCLSDMSSIF4xs2vNrEvwy72dmbWL8fx/Bk6sVHYzMNnd+wOTg+2vCc5/G3AocAhwW3WJpDk5fURXjujbnrtfX0jRtj1hhyMiTVwsCeJSIq+UPgBmBEtM83q6+zRgU6XiM4CJwfpE4MwqDj0BeMvdN7n7ZiLDfFRONM2OmXHHGUPZXVLGr19bEHY4ItLExTIfRO8qlj77cc1O7r42WF9H1bPTdQOiZ80pCMq+wcyuNLN8M8svKiraj7Aah34dM7nqqL68+OlqPlq2MexwRKQJi6mZq5kNNbNzzOySiqU+Lu6R7sH7VePq7o+5e5675+Xk5NRHWAnvumP6kdu2Bbe8PI+9pRo3UUTiI5ZmrrcBDwbLMcDdwOn7cc31ZtYlOHcXoLCKfVYD3aO2c4MyAVqkJXPHGUNYUridJzSxkIjESSxPEN8GxgPr3P1yYASQvR/XnESkXoPg859V7PMGcLyZtQ0qp48PyiQwbmAnThjSid9PXqQhwUUkLmJJELvcvRwoNbPWRP7i717LMQCY2bNEZqI7wMwKzOwK4C7gODNbDBwbbGNmeWb2JwB33wT8EpgeLHcEZRLl1tOGkGzGTS/MoVx9I0SknqXEsE9+MAfE40RaMG0n8ku/Vu5+fjVfja9i33zgu1HbTwJPxnKd5qpbmxbcetpgbnphLhM/XMHlozVduIjUn1oThLtfG6w+YmavA63dfU58w5JYnZPXnTfnr+eufy/kyP459OuYGXZIItJExFJJbWZ2kZnd6u4rgC1mdkj8Q5NYmBm//tYwWqYlM+G5WZSUqVWTiNSPWOog/ggcDlS8LtoGPBS3iGSfdczK4M6zhjGnoJg/vrM07HBEpImIJUEc6u7XAbsBgp7NaXGNSvbZycO6cObIrjw4ZTFzCraEHY6INAGxJIgSM0sm6NBmZjmA3mMkoNtPH0qHzHQmPDeb3SVlYYcjIo1cLAniAeAloKOZ3Qm8D/xvXKOSOslumcpvvzOcJYXb+e0bmlxIRPZPLK2Y/mpmM4g0TTXgTHfXSHEJ6sj+OVxyeE+eeH854wd15Ii+HcIOSUQaqWqfICoN7V0IPAs8Q2SojFiH+5YQ3HzSQHp3aMV/Pz+Hbbs1j7WI1E1Nr5g2ALOIDO2dz1dDfcc83LeEo2VaCveeM4K1xbu445XPwg5HRBqpmhLEA8Bm4HUiYyb1qafhvqUBjOrRlmuP7sfzMwqYNHtN2OGISCNUbYJw9x8AI4nMSX0x8KmZ3W1mGs+hkbjx2P4c1LMtN78whyWF28IOR0QamRpbMXnEO8BPgEeAy4kMsCeNQGpyEg9dMIoWqclc85eZ7NxbGnZIItKI1FRJ3crMLjCzfwKvAZnAQe7+eINFJ/utc3YGvz/vQJYUbednL84lMkeTiEjtamrmWggsBv4WfDqQZ2Z5AO7+YvzDk/owpn8HJhw7gHvfWkRer3ZcdFjPsEMSkUagpgTxPJGkcECwRHNACaIRue6Yfsz4YjN3vPIZw3OzGZ7bJuyQRCTBWVN65ZCXl+f5+WqBW53NO/Zy6oPvA/DqDWNo01JDaok0d2Y2w93zqvoulqE26juYA8xsVtSy1cx+UGmfo82sOGqfWxs6zqaobas0HrpwFIXbdvOj52ZrFjoRqVGDJwh3/9zdR7r7SOAgYCeRsZ4qe69iP3e/o2GjbLpGdm/Dz08dzOSFhTw8VUODi0j1YpkwKD2WsjoaDyx195X1dD6JwcWH9eT0EV25983P+WDphrDDEZEEFcsTRFXzT8c0J3UMziMyxlNVDjez2Wb2bzMbUt0JzOxKM8s3s/yioqJ6CqtpMzN+ffYw+uRkcsOzn7Jq086wQxKRBFRTP4jOZnYQ0MLMDjSzUcFyNNByfy9sZmnA6URaS1U2E+jp7iOAB4GXqzuPuz/m7nnunpeTk7O/YTUbrdJTePTig9hbWs4VE6ezVYP6iUglNT1BnADcA+QC9wH3BssE4Gf1cO2TgJnuvr7yF+6+1d23B+uvAalmpnGr61nfnEweuegglhXt4PpnPqVU81mLSJSaxmKa6O7HAJe5+zFRy+n11EnufKp5vRQ8vViwfkgQ58Z6uKZUckS/Dtx51lCmLSritknz1dNaRL5U64RBwGQzuw84KtieCtzh7sV1vaiZtQKOA66KKrsawN0fAb4NXGNmpcAu4DzXb664OffgHizfsJNHpi6lT04mV4zReIwiEluCeAKYB5wTbF8MPAWcXdeLuvsOoH2lskei1v8A/KGu55d995MTDmDlxh386tXP6NmuJccO7hR2SCISslhaMfV199vcfVmw3A5oPogmJinJuO+ckQzvls0Nf/uUeavr/IAoIk1ELAlil5mNqdgws9FEXvtIE9MiLZnHL82jbcs0rpg4nXXFu8MOSURCFEuCuAZ4yMxWmNlKIq9+rqrlGGmkOmZl8MRleezYU8YVE6ezY4/mkBBprmpNEO4+K+iPMBwY5u4Huvuc+IcmYRnYuTUPXnAgC9Zu5fvPfkqJmr+KNEuxDLWRHbRimgJMMbN7zSw7/qFJmI45oCO/OnMYUxYWMuG52ZRpYD+RZieWV0xPAtuItGI6B9hKpBWTNHEXHNqDn540kFdmr+F/XtJsdCLNTSzNXPu6+7eitm83s1nxCkgSy1Vj+7J9TykPTllCy7QUfn7qIII+jCLSxMWSIHaZ2Rh3fx/Uiqk5mnDcALbvKeXJ/ywnMyOFCccNCDskEWkAsSSIa4CJQb2DAZuAS+MalSQUM+Pnpwxmx55SHpi8mMz0ZK48qm/YYYlInNWaINx9FjDCzFoHRTuIDNOtlkzNSFKS8euzh7Njbxn/+9pCWqWncOGhPcMOS0TiqKbhvlub2U/N7A9mdhyRiupLgCV8NeyGNCPJScbvzhnJuIEdueXlebz86eqwQxKROKqpFdPTwAHAXOB7wDvAd4Cz3P2MBohNElBaShJ/vHAUh/Zux4+en83r89aGHZKIxElNCaKPu1/m7o8SGZp7MHBC8MpJmrGM1GT+dOnBDM/N5rpnPtWThEgTVVOC+HKKMXcvAwrcXYPzCACZ6Sk8fcWhHNyrLT98bhbPfPxF2CGJSD2rKUGMMLOtwbINGF6xbmZbGypASVyZ6Sn8+fJDOHpADj97aS5/em9Z2CGJSD2qaUa5ZHdvHSxZ7p4Std66uuOkeclITebRi/M4eVhnfvXqAu5/e5F6XIs0EbH0g4gLM1tBpGVUGVDq7nmVvjfg98DJwE4iU5/ObOg4pXZpKUk8cN6BtEidy/1vL2bHnlJ+drJ6XIs0dqEliMAx7r6hmu9OAvoHy6HAw8GnJKCU5CR+++3htEpP5vH3lrNjbxm/OmMoSUlKEiKNVdgJoiZnAP8XzEX9kZm1MbMu7q52lQkqKcm4/fQhtEpP4eF3l7JzTyn3fGcEKcmxjAkpIokmzAThwJtm5sCj7v5Ype+7AauitguCMiWIBGZm3HTiQDLTU/jtG5+zeWcJf7jgQLIyUsMOTUT2UZh/2o1x91FEXiVdZ2ZH1eUkZnalmeWbWX5RUVH9Rih1dt0x/fj12cN4f8kGvv3whxRs3hl2SCKyj0JLEO6+OvgsBF4CDqm0y2qge9R2blBW+TyPuXueu+fl5OTEK1ypg/MP6cHEyw9hTfEuznzoA2at2hJ2SCKyD0JJEGbWysyyKtaB44F5lXabBFxiEYcBxap/aHzG9O/AS9ceQYu0JM599ENem6v/hCKNRVhPEJ2A981sNvAJ8Kq7v25mV5vZ1cE+rwHLiAwO+DhwbTihyv7q1zGLl64dzZCurbn2rzP547tL1FdCpBGwpvSDmpeX5/n5+WGHIdXYXVLGf/9jDq/MXsM5ebn86sxhpKWohZNImMxsRuV+aBUSuZmrNDEZqck8cN5IendoxQOTF7Nq0y7+cMGBtM9MDzs0EamC/nyTBmVmTDhuAL87dwQzvtjMKQ+8z4yVm8IOS0SqoLztoYQAAAzMSURBVAQhoTjrwFxevOYI0lKSOPfRj/jTe8tULyGSYJQgJDRDu2XzrxvGMH5QR3716gKuenoGxbtKaj9QRBqEEoSEqnVGKo9cdBC3nDKIKQsLOfXB95hbUBx2WCKCEoQkADPju0f24e9XHU5pmfOthz/gLx+t1CsnkZApQUjCOKhnW1694UgO79ueW16ex41/m0XxTr1yEgmLEoQklHat0njqsoP58fEDeHXuWo6/fyrvfF4YdlgizZIShCScpCTj+nH9eenaI2idkcrlT03npn/MYdtuPU2INCQlCElYw3Pb8Mr3x3D12L48P2MVJ/xuGu8vrm5+KRGpb0oQktAyUpO5+aSB/OOaI8hIS+aiJz7mlpfnsmNPadihiTR5ShDSKIzq0ZbXbjiS747pzV8//oITfz+ND5bqaUIknpQgpNHISE3mllMH89xVh5NkxgWPf8z3n/2UtcW7wg5NpElSgpBG5+Be7Xj9xqO4cXx/3pi/jvH3TuWP7y5hT2lZ2KGJNClKENIotUhL5ofHDWDyhLGM6deBu1//nBPvf09NYkXqkRKENGrd27XksUvymPhfh2DA5U9N57sTp7Ny446wQxNp9JQgpEkYOyCH139wFD89aSAfLt3Icb+bxq//vYDNO/aGHZpIo9XgCcLMupvZO2b2mZnNN7Mbq9jnaDMrNrNZwXJrQ8cpjU9aShJXje3LlB8fzanDuvDYtGWM+c0U7nvzc40SK1IHDT7lqJl1Abq4+0wzywJmAGe6+2dR+xwN/NjdT92Xc2vKUYm2eP027n97Ma/OXUvrjBS+d2QfLh/Tm8x0TaQoUqGmKUcb/AnC3de6+8xgfRuwAOjW0HFI09e/UxYPXTiKV28YwyG923PvW4s48jdTeGTqUnbuVUc7kdo0+BPE1y5u1guYBgx1961R5UcDLwAFwBoiTxPzqznHlcCVAD169Dho5cqV8Q1aGq3Zq7Zw31uLmLqoiA6Z6Vw+uhcXHNKDtq3Swg5NJDQ1PUGEliDMLBOYCtzp7i9W+q41UO7u283sZOD37t6/tnPqFZPEYsbKTdz/9mLeW7yB9JQkzh6Vy+WjezGgU1bYoYk0uIRLEGaWCvwLeMPd74th/xVAnrvXOLaCEoTsi0Xrt/HUf1bw4swC9pSWc2T/DvzX6N6MHZBDUpKFHZ5Ig0ioBGFmBkwENrn7D6rZpzOw3t3dzA4B/gH09FqCVYKQuti8Yy/PfPIFT3+4knVbd9OnQysuG92LM0Z0I7tlatjhicRVoiWIMcB7wFygPCj+GdADwN0fMbPrgWuAUmAXMMHdP6jt3EoQsj9Kysr597x1PPH+cmav2kJachLjB3Xk7FG5jB2QQ1qKug1J05NQCSKelCCkvsxbXcyLM1czafZqNmzfS9uWqZw2oitnj8plRG42kQdhkcZPCUKkjkrKynl/8QZemFnAW5+tZ09pOX06tOKMkd04dnBHBndprWQhjZoShEg92Lq7hH/PXcuLM1fz8fJNAHRuncG4QR0Zd0BHRvfrQIu05JCjFNk3ShAi9axw227e/byIKQsKeW9xETv2lpGeksQRfdszbmBHxg7oSPd2LfR0IQlPCUIkjvaUljF9+WYmL1zP5AWFfLFpJwAds9LJ69WWvJ7tyOvVlsFdWpOSrIpuSSxKECINxN1ZWrSDD5dtJH/FJvJXbGb1lsiMdy3TkhnZvQ15vdoxvFs2B3TOIretnjIkXEoQIiFas2UX+Ss3M2PFJqav2MzCdVspD37sMtNTGNApkwM6t2Zg5ywO6JzFwM5ZtGmp4T+kYShBiCSQbbtLWLR+GwvXbePzdV99Rg9Jnt0ile7tWpDbpiW5bVuQ27YF3du1JLdtS7q1baERaaXe1JQg9H+ZSAPLykjloJ7tOKhnuy/L3J3CbXtYuG4bi9Zt44tNOynYvJMlRdt5d1Ehu0vKv3aOFqnJtM9Mo31mOh1apdEhM/3L7XatUslKTyUzI4WsjBSy0lPJykghMyOFVNWByD5QghBJAGZGp9YZdGqdwdgBOV/7zt3ZsH0vBZt3UrB5FwWbd7Fx+x427tjLhu17WFu8m3lritm4fS+l5TW/EUhPSaJVegoZKUlkpCaTnppMRmoSGSnBZ2oyaSlJpCQlkZZipCQlkZJspCYnkZoc2U5Osq8WM5KSjGSD5KTIepIZSQaGYQZJ9vXPin+vARa1X8V2ZI2v9g32/+obvvb91/etVJ9T8+Y3VK4Pqrx/TdVFla9ded9aa5q+sX/s50tNSWJUj7a1XWGfKUGIJDgzIycrnZysdA6s4ZeAu7N1Vykbd+xh+55Stu8uZdueUrbtLmX77hK2B+s79payu6Sc3SVl7C4pZ09pGbtLytiwvZTdJWWUlJVTUuaUlJVTWu6UlJZTUl5OaZnXmoAkHB0y08m/5dh6P2+TqoMwsyKgrhNCdABqHC02RIqtbhRb3Si2ummssfV095yqvmhSCWJ/mFl+dRU1YVNsdaPY6kax1U1TjE01ViIiUiUlCBERqZISxFceCzuAGii2ulFsdaPY6qbJxaY6CBERqZKeIEREpEpKECIiUqVmnyDM7EQz+9zMlpjZzWHHE83MVpjZXDObZWahDzJlZk+aWaGZzYsqa2dmb5nZ4uCz/rtz1j22X5jZ6uD+zTKzk0OIq7uZvWNmn5nZfDO7MSgP/b7VEFsi3LcMM/vEzGYHsd0elPc2s4+Dn9e/m1mDj2pYQ2x/NrPlUfdtZEPHFhVjspl9amb/Crbrdt/cvdkuQDKwFOgDpAGzgcFhxxUV3wqgQ9hxRMVzFDAKmBdVdjdwc7B+M/CbBIrtF8CPQ75nXYBRwXoWsAgYnAj3rYbYEuG+GZAZrKcCHwOHAc8B5wXljwDXJFBsfwa+HeZ9i4pxAvAM8K9gu073rbk/QRwCLHH3Ze6+F/gbcEbIMSUsd58GbKpUfAYwMVifCJzZoEEFqoktdO6+1t1nBuvbgAVANxLgvtUQW+g8YnuwmRosDowD/hGUh3XfqostIZhZLnAK8Kdg26jjfWvuCaIbsCpqu4AE+QEJOPCmmc0wsyvDDqYandx9bbC+DugUZjBVuN7M5gSvoEJ5/VXBzHoBBxL5izOh7lul2CAB7lvwmmQWUAi8ReRpf4u7lwa7hPbzWjk2d6+4b3cG9+13ZpYeRmzA/cBPgIohgNtTx/vW3BNEohvj7qOAk4DrzOyosAOqiUeeXxPmLyngYaAvMBJYC9wbViBmlgm8APzA3bdGfxf2fasitoS4b+5e5u4jgVwiT/sDw4ijKpVjM7OhwE+JxHgw0A64qaHjMrNTgUJ3n1Ef52vuCWI10D1qOzcoSwjuvjr4LAReIvJDkmjWm1kXgOCzMOR4vuTu64Mf5HLgcUK6f2aWSuQX8F/d/cWgOCHuW1WxJcp9q+DuW4B3gMOBNmZWMQp16D+vUbGdGLyyc3ffAzxFOPdtNHC6ma0g8sp8HPB76njfmnuCmA70D2r404DzgEkhxwSAmbUys6yKdeB4YF7NR4ViEnBpsH4p8M8QY/mail/AgbMI4f4F73+fABa4+31RX4V+36qLLUHuW46ZtQnWWwDHEakjeQf4drBbWPetqtgWRiV8I/KOv8Hvm7v/1N1z3b0Xkd9nU9z9Qup638KubQ97AU4m0npjKfA/YccTFVcfIq2qZgPzEyE24FkirxxKiLzHvILI+83JwGLgbaBdAsX2NDAXmEPkF3KXEOIaQ+T10RxgVrCcnAj3rYbYEuG+DQc+DWKYB9walPcBPgGWAM8D6QkU25Tgvs0D/kLQ0imsBTiar1ox1em+aagNERGpUnN/xSQiItVQghARkSopQYiISJWUIEREpEpKECIiUiUlCJF9YGZlUaN1zrJ6HAHYzHpFj0YrEraU2ncRkSi7PDLEgkiTpycIkXpgkbk77rbI/B2fmFm/oLyXmU0JBnCbbGY9gvJOZvZSMKfAbDM7IjhVspk9Hswz8GbQU1ckFEoQIvumRaVXTOdGfVfs7sOAPxAZURPgQWCiuw8H/go8EJQ/AEx19xFE5rGYH5T3Bx5y9yHAFuBbcf73iFRLPalF9oGZbXf3zCrKVwDj3H1ZMADeOndvb2YbiAxVURKUr3X3DmZWBOR6ZGC3inP0IjJ0dP9g+yYg1d1/Ff9/mcg36QlCpP54Nev7Yk/UehmqJ5QQKUGI1J9zoz4/DNY/IDKqJsCFwHvB+mTgGvhy8pnshgpSJFb660Rk37QIZhKr8Lq7VzR1bWtmc4g8BZwflH0feMrM/hsoAi4Pym8EHjOzK4g8KVxDZDRakYShOgiRehDUQeS5+4awYxGpL3rFJCIiVdIThIiIVElPECIiUiUlCBERqZIShIiIVEkJQkREqqQEISIiVfp/OW0fUoqWSdEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIZJHMiG-PUJ"
      },
      "source": [
        "# ***Решение задачи классификации***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUKWa5sBICHh"
      },
      "source": [
        "# Генерация названий строк\n",
        "ecoli_names = np.array(['Ecoli{}'.format(i) for i in range(data.X.shape[0])])"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Byb6qEABD3M1",
        "outputId": "5311c653-9b6a-484a-db9d-1601737e5490"
      },
      "source": [
        "data = pd.DataFrame(data.X, columns=data.inputs, index=ecoli_names)\n",
        "data"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mcg</th>\n",
              "      <th>Gvh</th>\n",
              "      <th>Lip</th>\n",
              "      <th>Chg</th>\n",
              "      <th>Aac</th>\n",
              "      <th>Alm1</th>\n",
              "      <th>Alm2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Ecoli0</th>\n",
              "      <td>49.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli1</th>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli2</th>\n",
              "      <td>56.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli3</th>\n",
              "      <td>59.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli4</th>\n",
              "      <td>23.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli331</th>\n",
              "      <td>74.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli332</th>\n",
              "      <td>71.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli333</th>\n",
              "      <td>61.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli334</th>\n",
              "      <td>59.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli335</th>\n",
              "      <td>74.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>336 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Mcg   Gvh   Lip  Chg   Aac  Alm1  Alm2\n",
              "Ecoli0    49.0  29.0  48.0  5.0  56.0  24.0  35.0\n",
              "Ecoli1     7.0   4.0  48.0  5.0  54.0  35.0  44.0\n",
              "Ecoli2    56.0   4.0  48.0  5.0  49.0  37.0  46.0\n",
              "Ecoli3    59.0  49.0  48.0  5.0  52.0  45.0  36.0\n",
              "Ecoli4    23.0  32.0  48.0  5.0  55.0  25.0  35.0\n",
              "...        ...   ...   ...  ...   ...   ...   ...\n",
              "Ecoli331  74.0  56.0  48.0  5.0  47.0  68.0   3.0\n",
              "Ecoli332  71.0  57.0  48.0  5.0  48.0  35.0  32.0\n",
              "Ecoli333  61.0   6.0  48.0  5.0  44.0  39.0  38.0\n",
              "Ecoli334  59.0  61.0  48.0  5.0  42.0  42.0  37.0\n",
              "Ecoli335  74.0  74.0  48.0  5.0  31.0  53.0  52.0\n",
              "\n",
              "[336 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XQoTJYfJUKn"
      },
      "source": [
        "*Теперь нормализуем данные*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58KMp_ub_c7B"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hJVDMYl_fSO"
      },
      "source": [
        "data_scaled = MinMaxScaler().fit_transform(data)"
      ],
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "KuMmSD2EX2mQ",
        "outputId": "b0f76e66-015b-4054-c400-4728ba90c265"
      },
      "source": [
        "pd.DataFrame(data_scaled, columns=ecoli.inputs, index=ecoli_names)"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mcg</th>\n",
              "      <th>Gvh</th>\n",
              "      <th>Lip</th>\n",
              "      <th>Chg</th>\n",
              "      <th>Aac</th>\n",
              "      <th>Alm1</th>\n",
              "      <th>Alm2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Ecoli0</th>\n",
              "      <td>0.550562</td>\n",
              "      <td>0.321839</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.247312</td>\n",
              "      <td>0.353535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli1</th>\n",
              "      <td>0.078652</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.613636</td>\n",
              "      <td>0.365591</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli2</th>\n",
              "      <td>0.629213</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.556818</td>\n",
              "      <td>0.387097</td>\n",
              "      <td>0.464646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli3</th>\n",
              "      <td>0.662921</td>\n",
              "      <td>0.551724</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.473118</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli4</th>\n",
              "      <td>0.258427</td>\n",
              "      <td>0.356322</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.258065</td>\n",
              "      <td>0.353535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli331</th>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.632184</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.534091</td>\n",
              "      <td>0.720430</td>\n",
              "      <td>0.030303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli332</th>\n",
              "      <td>0.797753</td>\n",
              "      <td>0.643678</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.365591</td>\n",
              "      <td>0.323232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli333</th>\n",
              "      <td>0.685393</td>\n",
              "      <td>0.057471</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.408602</td>\n",
              "      <td>0.383838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli334</th>\n",
              "      <td>0.662921</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.477273</td>\n",
              "      <td>0.440860</td>\n",
              "      <td>0.373737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecoli335</th>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.839080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.352273</td>\n",
              "      <td>0.559140</td>\n",
              "      <td>0.525253</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>336 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               Mcg       Gvh  Lip  Chg       Aac      Alm1      Alm2\n",
              "Ecoli0    0.550562  0.321839  1.0  1.0  0.636364  0.247312  0.353535\n",
              "Ecoli1    0.078652  0.034483  1.0  1.0  0.613636  0.365591  0.444444\n",
              "Ecoli2    0.629213  0.034483  1.0  1.0  0.556818  0.387097  0.464646\n",
              "Ecoli3    0.662921  0.551724  1.0  1.0  0.590909  0.473118  0.363636\n",
              "Ecoli4    0.258427  0.356322  1.0  1.0  0.625000  0.258065  0.353535\n",
              "...            ...       ...  ...  ...       ...       ...       ...\n",
              "Ecoli331  0.831461  0.632184  1.0  1.0  0.534091  0.720430  0.030303\n",
              "Ecoli332  0.797753  0.643678  1.0  1.0  0.545455  0.365591  0.323232\n",
              "Ecoli333  0.685393  0.057471  1.0  1.0  0.500000  0.408602  0.383838\n",
              "Ecoli334  0.662921  0.689655  1.0  1.0  0.477273  0.440860  0.373737\n",
              "Ecoli335  0.831461  0.839080  1.0  1.0  0.352273  0.559140  0.525253\n",
              "\n",
              "[336 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03WF3d1P0akQ",
        "outputId": "38e00810-f287-469f-a0f9-1088ee9e4c6a"
      },
      "source": [
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Создание классификатора\"\"\"\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(units=8, \n",
        "                                  input_shape=(7,)))\n",
        "  # Выходной слой с числом нейронов по числу классов\n",
        "  model.add(tf.keras.layers.Dense(30))\n",
        "  model.add(tf.keras.layers.Dense(8))\n",
        "\n",
        "  # Лосс-функция уже другая \n",
        "  model.compile(optimizer=tf.optimizers.Adam(lr=my_learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  return model  \n",
        "\n",
        "print(\"Defined create_model\")"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined create_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jeKC9Fi-aW3",
        "outputId": "d4b798b6-477c-4258-9883-a72f1d2fb1e6"
      },
      "source": [
        "def train_model(model, feature, label, epochs, batch_size):\n",
        "  \"\"\"Обучение модели\"\"\"\n",
        "\n",
        "  history = model.fit(x=feature,\n",
        "                      y=label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  epochs = history.epoch\n",
        "\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  acc = hist[\"accuracy\"]\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, acc\n",
        "\n",
        "print(\"Defined train_model\")"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined train_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iijN_vf1SQUL",
        "outputId": "d604f213-b39c-46fd-a0bd-6234d99901cb"
      },
      "source": [
        "def plot_the_loss_curve(epochs, acc):\n",
        "  \"\"\"График лосс-значений/эпохи\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Sparse Categorical Crossentropy \")\n",
        "\n",
        "  plt.plot(epochs, acc, label=\"Accuracy\")\n",
        "  plt.legend()\n",
        "  plt.ylim([acc.min()*0.97, acc.max()])\n",
        "  plt.show()\n",
        "\n",
        "print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the plot_the_model and plot_the_loss_curve functions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dl12vkJ8dBR"
      },
      "source": [
        "x = data_scaled\n",
        "y = ecoli.y"
      ],
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjKJf-cDza8O",
        "outputId": "19d87ab0-04c0-4baf-9a13-d5c67f212172"
      },
      "source": [
        "learning_rate=0.001\n",
        "epochs=300\n",
        "my_batch_size= 15\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, acc = train_model(my_model, x, \n",
        "                                                        y, epochs,\n",
        "                                                        my_batch_size)"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.9700 - accuracy: 0.2202\n",
            "Epoch 2/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1.6542 - accuracy: 0.4345\n",
            "Epoch 3/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1.4824 - accuracy: 0.4732\n",
            "Epoch 4/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.3934 - accuracy: 0.5119\n",
            "Epoch 5/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1.3367 - accuracy: 0.5565\n",
            "Epoch 6/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.2859 - accuracy: 0.5744\n",
            "Epoch 7/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.2447 - accuracy: 0.5804\n",
            "Epoch 8/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1.2041 - accuracy: 0.5804\n",
            "Epoch 9/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1.1687 - accuracy: 0.5893\n",
            "Epoch 10/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1.1331 - accuracy: 0.6339\n",
            "Epoch 11/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.0984 - accuracy: 0.6280\n",
            "Epoch 12/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.0665 - accuracy: 0.6488\n",
            "Epoch 13/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 1.0395 - accuracy: 0.6756\n",
            "Epoch 14/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.0116 - accuracy: 0.6726\n",
            "Epoch 15/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.9884 - accuracy: 0.6756\n",
            "Epoch 16/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.9650 - accuracy: 0.6815\n",
            "Epoch 17/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.9435 - accuracy: 0.7083\n",
            "Epoch 18/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.9228 - accuracy: 0.6935\n",
            "Epoch 19/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.9085 - accuracy: 0.6994\n",
            "Epoch 20/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.8892 - accuracy: 0.7113\n",
            "Epoch 21/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.8757 - accuracy: 0.7054\n",
            "Epoch 22/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.8627 - accuracy: 0.7113\n",
            "Epoch 23/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.8505 - accuracy: 0.7202\n",
            "Epoch 24/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.8374 - accuracy: 0.7262\n",
            "Epoch 25/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.8242 - accuracy: 0.7232\n",
            "Epoch 26/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.8132 - accuracy: 0.7292\n",
            "Epoch 27/300\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8050 - accuracy: 0.7411\n",
            "Epoch 28/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7982 - accuracy: 0.7411\n",
            "Epoch 29/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7909 - accuracy: 0.7321\n",
            "Epoch 30/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7799 - accuracy: 0.7530\n",
            "Epoch 31/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7761 - accuracy: 0.7649\n",
            "Epoch 32/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7663 - accuracy: 0.7440\n",
            "Epoch 33/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7604 - accuracy: 0.7530\n",
            "Epoch 34/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7565 - accuracy: 0.7589\n",
            "Epoch 35/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7502 - accuracy: 0.7649\n",
            "Epoch 36/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7456 - accuracy: 0.7589\n",
            "Epoch 37/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7477 - accuracy: 0.7619\n",
            "Epoch 38/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7355 - accuracy: 0.7679\n",
            "Epoch 39/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7344 - accuracy: 0.7619\n",
            "Epoch 40/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.7679\n",
            "Epoch 41/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7322 - accuracy: 0.7679\n",
            "Epoch 42/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.7679\n",
            "Epoch 43/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.7798\n",
            "Epoch 44/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7138 - accuracy: 0.7738\n",
            "Epoch 45/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.7738\n",
            "Epoch 46/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.7708\n",
            "Epoch 47/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7076 - accuracy: 0.7738\n",
            "Epoch 48/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.7649\n",
            "Epoch 49/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.7768\n",
            "Epoch 50/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.7708\n",
            "Epoch 51/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.7857\n",
            "Epoch 52/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.7560\n",
            "Epoch 53/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.7768\n",
            "Epoch 54/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.7798\n",
            "Epoch 55/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.7738\n",
            "Epoch 56/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.7917\n",
            "Epoch 57/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.7679\n",
            "Epoch 58/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.7619\n",
            "Epoch 59/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.7619\n",
            "Epoch 60/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.7857\n",
            "Epoch 61/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.7738\n",
            "Epoch 62/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.7708\n",
            "Epoch 63/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.7738\n",
            "Epoch 64/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.7768\n",
            "Epoch 65/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.7827\n",
            "Epoch 66/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.7738\n",
            "Epoch 67/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.7887\n",
            "Epoch 68/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.7768\n",
            "Epoch 69/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.7768\n",
            "Epoch 70/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.7798\n",
            "Epoch 71/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.7827\n",
            "Epoch 72/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.7887\n",
            "Epoch 73/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.7768\n",
            "Epoch 74/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6689 - accuracy: 0.7827\n",
            "Epoch 75/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.7887\n",
            "Epoch 76/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.7917\n",
            "Epoch 77/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.7857\n",
            "Epoch 78/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.7768\n",
            "Epoch 79/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.7887\n",
            "Epoch 80/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.7857\n",
            "Epoch 81/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.7946\n",
            "Epoch 82/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.7827\n",
            "Epoch 83/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.7887\n",
            "Epoch 84/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.7768\n",
            "Epoch 85/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.7887\n",
            "Epoch 86/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.7708\n",
            "Epoch 87/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.7946\n",
            "Epoch 88/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.7946\n",
            "Epoch 89/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.7798\n",
            "Epoch 90/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.7798\n",
            "Epoch 91/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.7917\n",
            "Epoch 92/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.7857\n",
            "Epoch 93/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.8036\n",
            "Epoch 94/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.7708\n",
            "Epoch 95/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.7946\n",
            "Epoch 96/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.7857\n",
            "Epoch 97/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.7946\n",
            "Epoch 98/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.8065\n",
            "Epoch 99/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.7798\n",
            "Epoch 100/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.8065\n",
            "Epoch 101/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.8036\n",
            "Epoch 102/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.7857\n",
            "Epoch 103/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.8036\n",
            "Epoch 104/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.7946\n",
            "Epoch 105/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.8006\n",
            "Epoch 106/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.8006\n",
            "Epoch 107/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.7708\n",
            "Epoch 108/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.7917\n",
            "Epoch 109/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.8036\n",
            "Epoch 110/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.7946\n",
            "Epoch 111/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.7946\n",
            "Epoch 112/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.8006\n",
            "Epoch 113/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.7946\n",
            "Epoch 114/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.7857\n",
            "Epoch 115/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.8006\n",
            "Epoch 116/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.7738\n",
            "Epoch 117/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.8065\n",
            "Epoch 118/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.7887\n",
            "Epoch 119/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.8065\n",
            "Epoch 120/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.7976\n",
            "Epoch 121/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.8065\n",
            "Epoch 122/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.7946\n",
            "Epoch 123/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.7917\n",
            "Epoch 124/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.8036\n",
            "Epoch 125/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.8006\n",
            "Epoch 126/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.8036\n",
            "Epoch 127/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.8065\n",
            "Epoch 128/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.7946\n",
            "Epoch 129/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.7857\n",
            "Epoch 130/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.8065\n",
            "Epoch 131/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.8125\n",
            "Epoch 132/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.7887\n",
            "Epoch 133/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.8036\n",
            "Epoch 134/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.7917\n",
            "Epoch 135/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.8006\n",
            "Epoch 136/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.8036\n",
            "Epoch 137/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.8036\n",
            "Epoch 138/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.8006\n",
            "Epoch 139/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.7976\n",
            "Epoch 140/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.8006\n",
            "Epoch 141/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.7857\n",
            "Epoch 142/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.8006\n",
            "Epoch 143/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.7946\n",
            "Epoch 144/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.8036\n",
            "Epoch 145/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.8036\n",
            "Epoch 146/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.7976\n",
            "Epoch 147/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.8006\n",
            "Epoch 148/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.7917\n",
            "Epoch 149/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.8095\n",
            "Epoch 150/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.7946\n",
            "Epoch 151/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.8036\n",
            "Epoch 152/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.7917\n",
            "Epoch 153/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.8006\n",
            "Epoch 154/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.8065\n",
            "Epoch 155/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.7768\n",
            "Epoch 156/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.8036\n",
            "Epoch 157/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.7946\n",
            "Epoch 158/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.7917\n",
            "Epoch 159/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.7917\n",
            "Epoch 160/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.8125\n",
            "Epoch 161/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.7976\n",
            "Epoch 162/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.8036\n",
            "Epoch 163/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.7976\n",
            "Epoch 164/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.8036\n",
            "Epoch 165/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.8036\n",
            "Epoch 166/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.8065\n",
            "Epoch 167/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.8006\n",
            "Epoch 168/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.7917\n",
            "Epoch 169/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.8095\n",
            "Epoch 170/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.8036\n",
            "Epoch 171/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.8036\n",
            "Epoch 172/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.8006\n",
            "Epoch 173/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.8036\n",
            "Epoch 174/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.8065\n",
            "Epoch 175/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.8006\n",
            "Epoch 176/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.7946\n",
            "Epoch 177/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.8006\n",
            "Epoch 178/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.8006\n",
            "Epoch 179/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.8006\n",
            "Epoch 180/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.8095\n",
            "Epoch 181/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.8006\n",
            "Epoch 182/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.8095\n",
            "Epoch 183/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.8065\n",
            "Epoch 184/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.8065\n",
            "Epoch 185/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.8065\n",
            "Epoch 186/300\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.8095\n",
            "Epoch 187/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.8065\n",
            "Epoch 188/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.8095\n",
            "Epoch 189/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.8036\n",
            "Epoch 190/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.8065\n",
            "Epoch 191/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.8065\n",
            "Epoch 192/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.8006\n",
            "Epoch 193/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.8036\n",
            "Epoch 194/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.7917\n",
            "Epoch 195/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.8095\n",
            "Epoch 196/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.7976\n",
            "Epoch 197/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.8125\n",
            "Epoch 198/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.7946\n",
            "Epoch 199/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.8095\n",
            "Epoch 200/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.8036\n",
            "Epoch 201/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.7976\n",
            "Epoch 202/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.8065\n",
            "Epoch 203/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.8095\n",
            "Epoch 204/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.8036\n",
            "Epoch 205/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.7976\n",
            "Epoch 206/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.8065\n",
            "Epoch 207/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.7917\n",
            "Epoch 208/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.8006\n",
            "Epoch 209/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.8065\n",
            "Epoch 210/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.8065\n",
            "Epoch 211/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.8095\n",
            "Epoch 212/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.8155\n",
            "Epoch 213/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.8095\n",
            "Epoch 214/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.8095\n",
            "Epoch 215/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.8155\n",
            "Epoch 216/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.8036\n",
            "Epoch 217/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.8036\n",
            "Epoch 218/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.8065\n",
            "Epoch 219/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.8095\n",
            "Epoch 220/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.8095\n",
            "Epoch 221/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6357 - accuracy: 0.8095\n",
            "Epoch 222/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.8065\n",
            "Epoch 223/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.8006\n",
            "Epoch 224/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.8095\n",
            "Epoch 225/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.8065\n",
            "Epoch 226/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.8036\n",
            "Epoch 227/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.8006\n",
            "Epoch 228/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.8125\n",
            "Epoch 229/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.7976\n",
            "Epoch 230/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.8095\n",
            "Epoch 231/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.8125\n",
            "Epoch 232/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.7976\n",
            "Epoch 233/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.8095\n",
            "Epoch 234/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.8006\n",
            "Epoch 235/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.8095\n",
            "Epoch 236/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.8065\n",
            "Epoch 237/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.7946\n",
            "Epoch 238/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.8036\n",
            "Epoch 239/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.8065\n",
            "Epoch 240/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.8036\n",
            "Epoch 241/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.8006\n",
            "Epoch 242/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.8036\n",
            "Epoch 243/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.8155\n",
            "Epoch 244/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.8095\n",
            "Epoch 245/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.7946\n",
            "Epoch 246/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6342 - accuracy: 0.8065\n",
            "Epoch 247/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.7946\n",
            "Epoch 248/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.8095\n",
            "Epoch 249/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.8065\n",
            "Epoch 250/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.8065\n",
            "Epoch 251/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.8065\n",
            "Epoch 252/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.8095\n",
            "Epoch 253/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.8095\n",
            "Epoch 254/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.8155\n",
            "Epoch 255/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.8095\n",
            "Epoch 256/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.8095\n",
            "Epoch 257/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.8006\n",
            "Epoch 258/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.8095\n",
            "Epoch 259/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.8065\n",
            "Epoch 260/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.7976\n",
            "Epoch 261/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.8125\n",
            "Epoch 262/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 0.8155\n",
            "Epoch 263/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.8095\n",
            "Epoch 264/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.7917\n",
            "Epoch 265/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.8185\n",
            "Epoch 266/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.8155\n",
            "Epoch 267/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.8065\n",
            "Epoch 268/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.8065\n",
            "Epoch 269/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.7976\n",
            "Epoch 270/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.8065\n",
            "Epoch 271/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.8095\n",
            "Epoch 272/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.8036\n",
            "Epoch 273/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.8065\n",
            "Epoch 274/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.8065\n",
            "Epoch 275/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.8125\n",
            "Epoch 276/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.8065\n",
            "Epoch 277/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.8095\n",
            "Epoch 278/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.8036\n",
            "Epoch 279/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6302 - accuracy: 0.8125\n",
            "Epoch 280/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.8125\n",
            "Epoch 281/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.8095\n",
            "Epoch 282/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.8036\n",
            "Epoch 283/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.8155\n",
            "Epoch 284/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.8095\n",
            "Epoch 285/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.7946\n",
            "Epoch 286/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.8036\n",
            "Epoch 287/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.8065\n",
            "Epoch 288/300\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.8036\n",
            "Epoch 289/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.8125\n",
            "Epoch 290/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.8095\n",
            "Epoch 291/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.8155\n",
            "Epoch 292/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.8155\n",
            "Epoch 293/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.8125\n",
            "Epoch 294/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.8006\n",
            "Epoch 295/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.8036\n",
            "Epoch 296/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.8065\n",
            "Epoch 297/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.8065\n",
            "Epoch 298/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.8065\n",
            "Epoch 299/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.8125\n",
            "Epoch 300/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.8036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "bkfjTJhqSqPx",
        "outputId": "765d71aa-d649-4654-b3cc-203b768ace2f"
      },
      "source": [
        "plot_the_loss_curve(epochs, acc)"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOu6-STG2pB6"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "dataset = fetch_openml('har')\n",
        "X = StandardScaler().fit_transform(dataset.data)\n",
        "Y = dataset.target\n",
        "Y_new = []\n",
        "for i in range(len(Y)):\n",
        "  Y_new.append(int(Y[i]))"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iBESH4h32pK"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh7-R48Y34M0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "features = X.shape[1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X[:, :features], \n",
        "    Y, \n",
        "    test_size=0.3, \n",
        "    shuffle=True)"
      ],
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsmkW_0q4QUG",
        "outputId": "52c93c76-b513-420e-abcd-bbca2b559af1"
      },
      "source": [
        "kf = KFold(n_splits=5)\n",
        "accs = []\n",
        "for train_index, test_index in kf.split(X):\n",
        "  for i in range(0, 5):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = Y[train_index], Y[test_index]\n",
        "    model = LinearSVC(tol=1e1)\n",
        "    model.fit(X_train, y_train)\n",
        "    predicted = model.predict(X_test)\n",
        "    acc = accuracy_score(predicted, y_test)\n",
        "    accs.append(acc)\n",
        "print(np.mean(accs))"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9376839261211729\n"
          ]
        }
      ]
    }
  ]
}